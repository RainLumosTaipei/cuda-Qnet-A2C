`CartPole`（倒立摆）是强化学习中的**经典入门环境**，常被用作算法测试的"Hello World"。它形象地展示了平衡控制问题，非常适合理解强化学习的基本原理。


### **一、环境介绍**
#### **物理模型**
- 一根杆（Pole）通过铰链连接在小车上（Cart）
- 小车可以在轨道上左右移动（一维空间）
- 目标：通过控制小车的移动，使杆保持垂直不倒

#### **游戏规则**
- **动作空间**：离散的2个动作
  - `0`：向左推小车
  - `1`：向右推小车
- **状态空间**：连续的4维向量
  1. 小车位置（-4.8到4.8）
  2. 小车速度（-∞到+∞）
  3. 杆的角度（-0.418到0.418弧度，约±24°）
  4. 杆的角速度（-∞到+∞）
- **终止条件**（满足任一即结束）：
  - 杆的角度超过±12°
  - 小车位置超过±2.4
  - 达到最大步数（默认200步）
- **奖励机制**：每坚持一步得1分，目标是最大化总奖励


### **二、为什么选择CartPole？**
1. **简单直观**：状态空间小，动作空间离散，易于理解
2. **计算轻量**：无需复杂硬件，普通电脑即可快速训练
3. **教育价值高**：清晰展示了「平衡」这一核心控制问题
4. **适合测试算法**：大多数RL算法都能在CartPole上快速验证效果


### **三、解决CartPole的基本思路**
#### **1. 随机策略（Baseline）**
- 随机选择向左或向右推
- 通常只能坚持10-20步，总奖励≈10-20

#### **2. 启发式规则（非RL方法）**
- 简单规则：如果杆向左倾斜，就向左推；向右倾斜，就向右推
- 可以坚持50-100步，但不够稳定

#### **3. 强化学习方法**
- **策略梯度类**：如REINFORCE、PPO
- **值函数类**：如DQN、SARSA
- **演员-评论家类**：如A2C、A3C
